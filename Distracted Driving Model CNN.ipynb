{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "\n",
    "from six.moves import xrange\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import Image\n",
    "\n",
    "import math\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "DATA_PATH = '../data/statefarmchallenge/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to recoreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading csv\n",
      "Generating validation record\n",
      "Loading batch\n",
      "Writing ../data/statefarmchallenge/validation.tfrecords\n",
      "Loading batch\n",
      "Writing ../data/statefarmchallenge/validation.tfrecords\n",
      "Loading batch\n",
      "Writing ../data/statefarmchallenge/validation.tfrecords\n",
      "Loading batch\n",
      "Writing ../data/statefarmchallenge/validation.tfrecords\n",
      "Loading batch\n",
      "Writing ../data/statefarmchallenge/validation.tfrecords\n",
      "Loading batch\n",
      "Writing ../data/statefarmchallenge/validation.tfrecords\n",
      "Generating train record\n",
      "Loading batch\n"
     ]
    }
   ],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _byte_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def convert(images, labels, name):\n",
    "    \"\"\"Convert images and labesl to TFRecord\"\"\"\n",
    "    num_examples = labels.shape[0]\n",
    "    if images.shape[0] != num_examples:\n",
    "        raise ValueError(\"images size {} did not match labels size {}\"\n",
    "                         .format(images.shape[0], num_examples))\n",
    "        \n",
    "    rows = images.shape[1]\n",
    "    cols = images.shape[2]\n",
    "    depth = images.shape[3]\n",
    "\n",
    "    filename = os.path.join(DATA_PATH, name + '.tfrecords')\n",
    "    print('Writing', filename)\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    for index in range(num_examples):\n",
    "        image_raw = images[index].tostring()\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'height': _int64_feature(rows),\n",
    "            'width': _int64_feature(cols),\n",
    "            'depth': _int64_feature(depth),\n",
    "            'label': _int64_feature(labels[index]),\n",
    "            'image_raw': _byte_feature(image_raw)}))\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()\n",
    "       \n",
    "\n",
    "def load_image(infilename):\n",
    "    \"\"\"Load our image and return as numpy array\"\"\"\n",
    "    img = Image.open(infilename)\n",
    "    data = np.asarray(img)\n",
    "    return data\n",
    "\n",
    "\n",
    "def load(rows, data_path):\n",
    "    \"\"\"Load a batch of images & labels for converting\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    print('Loading batch')\n",
    "    for row in rows:\n",
    "        path = os.path.join(data_path, row[1], row[2])\n",
    "        data = load_image(path)\n",
    "        images.append(data)\n",
    "        labels.append(int(row[1][1]))\n",
    "    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "\n",
    "\n",
    "def gen_record(size, records, name, num_batches, data_path):\n",
    "    \"\"\"Generate a record file by batching data\"\"\"\n",
    "    examples_per_batch = size // num_batches\n",
    "    \n",
    "    if examples_per_batch <= 1:\n",
    "        raise ValueError('Batch size must be greater than 1')\n",
    "        \n",
    "    print(\"Generating \" + name + \" record\")\n",
    "    for i in xrange(num_batches):\n",
    "        k = i * examples_per_batch\n",
    "        record_b = records[k : k + examples_per_batch]\n",
    "\n",
    "        images_b, labels_b = load(record_b, data_path)\n",
    "\n",
    "        convert(images_b, labels_b, name)\n",
    "                \n",
    "    # What about left overs???\n",
    "    records_processed = examples_per_batch * num_batches\n",
    "    left_over = size - records_processed\n",
    "    \n",
    "    if left_over > 0:\n",
    "        record_b = records[records_processed:]\n",
    "        images_b, labels_b = load(record_b, data_path)\n",
    "        convert(images_b, labels_b, name)\n",
    "        \n",
    "        \n",
    "\n",
    "def read_csv(path):\n",
    "    \"\"\"Read CSV record and return as list\"\"\"\n",
    "    print('Reading csv')\n",
    "                \n",
    "    with open(path, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        records = list(reader)\n",
    "    \n",
    "    return records\n",
    "        \n",
    "\n",
    "    \n",
    "def main(argv):\n",
    "    records = read_csv(DATA_PATH + 'driver_imgs_list.csv')\n",
    "    num_examples = len(records)\n",
    "    \n",
    "    # Generate validation TFRecords (20%)\n",
    "    validation_size = num_examples // 5\n",
    "    val_records = records[ : validation_size]\n",
    "    gen_record(size=validation_size, \n",
    "               records=val_records, \n",
    "               name='validation', \n",
    "               num_batches=5, \n",
    "               data_path=DATA_PATH + 'imgs/train/')\n",
    "\n",
    "    \n",
    "    # Generate training TFRecords\n",
    "    train_size = num_examples - validation_size\n",
    "    train_records = records[validation_size : ]\n",
    "    gen_record(size=train_size, \n",
    "               records=train_records, \n",
    "               name='train', \n",
    "               num_batches=10, \n",
    "               data_path=DATA_PATH + 'imgs/train')\n",
    "                \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-62efe6f51668>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-62efe6f51668>\"\u001b[1;36m, line \u001b[1;32m22\u001b[0m\n\u001b[1;33m    def input_pipeline():\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "TRAIN_FILE = 'train.tfrecords'\n",
    "VALIDATION_FILE = 'validation.tfrecords'\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 2\n",
    "height = 480\n",
    "width = 640\n",
    "depth = 3\n",
    "image_size = height * width * depth\n",
    "\n",
    "    \n",
    "def input_pipeline():\n",
    "    # Create queue for csv file\n",
    "    file_queue = tf.train.string_input_producer([DATA_FILE_PATH], num_epochs=num_epochs)\n",
    "\n",
    "    image, label = decode_and_process_img(file_queue)\n",
    "\n",
    "    images, labels = tf.train.shuffle_batch([image, label], batch_size=batch_size, \n",
    "                                            num_threads=6,\n",
    "                                            capacity=1000 + 3 * batch_size,\n",
    "                                            min_after_dequeue=1000)\n",
    "\n",
    "    return image_batch, label_batch\n",
    "\n",
    "\n",
    "\n",
    "def read_and_decode(filename_queue):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(\n",
    "      serialized_example,\n",
    "      # Defaults are not specified since both keys are required.\n",
    "      features={\n",
    "            'height' : tf.FixedLenFe,\n",
    "            'width' :,\n",
    "            'depth' :,\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64),\n",
    "      })\n",
    "\n",
    "    # Convert from a scalar string to unit8 tensor\n",
    "    image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "    tf.reshape(image, [height, width, depth])\n",
    "\n",
    "    # OPTIONAL: Could reshape image and apply distortions or whitening here\n",
    "\n",
    "\n",
    "    # Convert from [0, 255] -> [-0.5, 0.5] floats.\n",
    "    image = tf.cast(image, tf.float32) * (1. / 255) - 0.5\n",
    "\n",
    "    # Convert label from a scalar uint8 tensor to an int32 scalar.\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "    \n",
    "def inputs(train, batch_size, num_epochs):\n",
    "    if not num_epochs: num_epochs = None\n",
    "    filename = os.path.join(DATA_PATH,\n",
    "                          TRAIN_FILE if train else VALIDATION_FILE)\n",
    "\n",
    "    with tf.name_scope('input'):\n",
    "        filename_queue = tf.train.string_input_producer(\n",
    "            [filename], num_epochs=num_epochs)\n",
    "\n",
    "    # Even when reading in multiple threads, share the filename\n",
    "    # queue.\n",
    "    image, label = read_and_decode(filename_queue)\n",
    "\n",
    "    # Shuffle the examples and collect them into batch_size batches.\n",
    "    # (Internally uses a RandomShuffleQueue.)\n",
    "    # We run this in two threads to avoid being a bottleneck.\n",
    "    images, sparse_labels = tf.train.shuffle_batch(\n",
    "        [image, label], batch_size=batch_size, num_threads=2,\n",
    "        capacity=1000 + 3 * batch_size,\n",
    "        # Ensures a minimum amount of shuffling of examples.\n",
    "        min_after_dequeue=1000)\n",
    "\n",
    "    return images, sparse_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use tf records to run our model as a threaded queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _dense_to_one_hot(labels_dense, num_classes):\n",
    "    \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "\n",
    "def _variabel_on_cpu(name, shape, initializer, regularizer):\n",
    "    \"\"\"Helper to create a Variable stored on CPU memory.\"\"\"\"\n",
    "    with tf.device('\\cpu0:'):\n",
    "        var = tf.get_variable(name, shape, initializer=initializer, regularizer=regularizer)\n",
    "    \n",
    "    return var\n",
    "\n",
    "\n",
    "\n",
    "def _variable_summaries(var, name):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor.\"\"\"\n",
    "     with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.scalar_summary('mean/' + name, mean)\n",
    "    with tf.name_scope('stddev'):\n",
    "        stddev = tf.sqrt(tf.reduce_sum(tf.square(var - mean)))\n",
    "   \n",
    "    tf.scalar_summary('sttdev/' + name, stddev)\n",
    "    tf.scalar_summary('max/' + name, tf.reduce_max(var))\n",
    "    tf.scalar_summary('min/' + name, tf.reduce_min(var))\n",
    "    tf.histogram_summary(name, var)\n",
    "\n",
    "    \n",
    "def local_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n",
    "    \"\"\"Reusable code for making a simple neural net layer.\n",
    "\n",
    "    It does a matrix multiply, bias add, and then uses relu to nonlinearize.\n",
    "    It also sets up name scoping so that the resultant graph is easy to read,\n",
    "    and adds a number of summary ops.\n",
    "    \"\"\"\n",
    "    # Adding a name scope ensures logical grouping of the layers in the graph.\n",
    "    with tf.name_scope(layer_name):\n",
    "        # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            weights = _variable_with_weight_decay([input_dim, output_dim])\n",
    "            variable_summaries(weights, layer_name + '/weights')\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = bias_variable([output_dim])\n",
    "            variable_summaries(biases, layer_name + '/biases')\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            preactivate = tf.matmul(input_tensor, weights) + biases\n",
    "            tf.histogram_summary(layer_name + '/pre_activations', preactivate)\n",
    "            \n",
    "    activations = act(preactivate, 'activation')\n",
    "    tf.histogram_summary(layer_name + '/activations', activations)\n",
    "    return activations\n",
    "\n",
    "\n",
    "def conv_relu(input, kernel_shape, bias_shape):\n",
    "    # Create variable named \"weights\".\n",
    "    weights = _variabel_on_cpu(\"weights\", kernel_shape,\n",
    "        initializer=tf.uniform_unit_scaling_initializer(factor=2.0 / kernel_shape[0]),\n",
    "        regularizer=tf.contrib.layers.l2_regularizer(.001))\n",
    "    \n",
    "    # Create variable named \"biases\".\n",
    "    biases = tf.get_variable(\"biases\", bias_shape, initializer=tf.constant_initializer(0.0))\n",
    "    conv = tf.nn.conv2d(input, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv + biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    " - add images to summary\n",
    " - change learning rate to exp step\n",
    " - examine learning \n",
    " - clean up layers with funtions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "\n",
    "# Convolution output depths \n",
    "depth_1 = 32\n",
    "depth_2 = 64\n",
    "depth_3 = 64\n",
    "\n",
    "# Kernel shapes\n",
    "patch_size = 10\n",
    "num_channels = 3\n",
    "\n",
    "# Local layer size\n",
    "num_hidden = 2048\n",
    "\n",
    "\n",
    "learning_rate = .01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inference(images, keep_prob):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    images: Images placeholder, from inputs().\n",
    "    Returns:\n",
    "    softmax_linear: Output tensor with the computed logits.\n",
    "    \"\"\"\n",
    "\n",
    "    # Conv1 /w pooling\n",
    "    with tf.name_scope('conv1') as scope:\n",
    "        conv1 = conv_relu(images, [patch_size, patch_size, channels, depth_1], [depth1])     \n",
    "        pool1 = tf.nn.avg_pool(conv1, [1, 6, 6, 1], [1, 2, 2, 1], padding='SAME')\n",
    "        norm1 = tf.nn.local_response_normalization(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "\n",
    "        \n",
    "    # Conv2 /w pooling \n",
    "    with tf.name_scope('conv2') as scope:\n",
    "        weights = tf.Variable(tf.truncated_normal(\n",
    "              [patch_size, patch_size, depth1, depth2], stddev=0.01))\n",
    "        biases = tf.Variable(tf.constant(1.0, shape=[depth2]))\n",
    "        conv = tf.nn.conv2d(norm1, weights, [1, 1, 1, 1], padding='SAME', name='conv2')\n",
    "        conv2 = tf.nn.relu(conv, name=scope)\n",
    "    \n",
    "    pool2 = tf.nn.avg_pool(conv2, [1, 6, 6, 1], [1, 2, 2, 1], padding='SAME', name='pool2')\n",
    "    norm2 = tf.nn.local_response_normalization(pool2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm2')\n",
    "    \n",
    "    # Conv3 /w pooling\n",
    "    with tf.name_scope('conv3') as scope:\n",
    "        weights = tf.Variable(tf.truncated_normal(\n",
    "              [patch_size, patch_size, depth2, depth3], stddev=0.01))\n",
    "        biases = tf.Variable(tf.constant(1.0, shape=[depth3]))\n",
    "        conv = tf.nn.conv2d(norm2, weights, [1, 1, 1, 1], padding='SAME', name='conv3')\n",
    "        conv3 = tf.nn.relu(conv, name=scope)\n",
    "    \n",
    "    pool3 = tf.nn.avg_pool(conv3, [1, 6, 6, 1], [1, 2, 2, 1], padding='SAME', name='pool3')\n",
    "    norm3 = tf.nn.local_response_normalization(pool3, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm3') \n",
    "    shape = norm3.get_shape().as_list()\n",
    "    reshape = tf.reshape(norm3, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "        \n",
    "        \n",
    "    #local4\n",
    "    with tf.name_scope('local3') as scope:\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([image_size, num_hidden],\n",
    "                                stddev=1.0 / math.sqrt(float(num_hidden))))\n",
    "\n",
    "        biases = tf.Variable(tf.zeros([num_hidden]))\n",
    "        z = tf.matmul(reshape, weights) + biases\n",
    "        local4 = tf.nn.relu(z, name=scope)\n",
    "        drop = tf.nn.dropout(local4, keep_prob)\n",
    "\n",
    "    # local5\n",
    "    with tf.name_scope('local4') as scope:\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([num_hidden, num_hidden],\n",
    "                                stddev=1.0 / math.sqrt(float(num_hidden))), name='weights_5')\n",
    "\n",
    "        biases = tf.Variable(tf.zeros([num_hidden]), name='biases_5')\n",
    "        z = tf.matmul(drop, weights) + biases\n",
    "        local5 = tf.nn.relu(z, name=scope)\n",
    "        drop = tf.nn.dropout(local5, keep_prob)\n",
    "        \n",
    "        \n",
    "    # Linear\n",
    "    with tf.name_scope('softmax_linear'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([num_hidden, NUM_CLASSES],\n",
    "                                stddev=1.0 / math.sqrt(float(num_hidden))), name='weights_s')\n",
    "\n",
    "        biases = tf.Variable(tf.zeros([NUM_CLASSES]), name='biases_s')\n",
    "        logits = tf.matmul(drop, weights) + biases\n",
    "        \n",
    "    return logits\n",
    "\n",
    "\n",
    "def loss(logits, labels):\n",
    "    \"\"\"\"\n",
    "    Calculates the loss from the logits and the labels.\n",
    "    Args:\n",
    "    logits: Logits tensor, float - [batch_size, NUM_CLASSES].\n",
    "    labels: Labels tensor, int64 - [batch_size].\n",
    "    Returns:\n",
    "    loss: Loss tensor of type float.\n",
    "    \"\"\"\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels, name='xentropy')\n",
    "    loss = tf.reduce_mean(cross_entropy, name='xentropy_mean')\n",
    "    return loss\n",
    "\n",
    "\n",
    "def training(loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Sets up the training Ops.\n",
    "    Creates a summarizer to track the loss over time in TensorBoard.\n",
    "    Creates an optimizer and applies the gradients to all trainable variables.\n",
    "    The Op returned by this function is what must be passed to the\n",
    "    `sess.run()` call to cause the model to train.\n",
    "    Args:\n",
    "    loss: Loss tensor, from loss().\n",
    "    learning_rate: The learning rate to use for gradient descent.\n",
    "    Returns:\n",
    "    train_op: The Op for training.\n",
    "    \"\"\"\n",
    "    # Add a scalar summary for the snapshot loss. (Tensor board)\n",
    "    tf.scalar_summary('loss', loss)\n",
    "\n",
    "    # Create a variable to track the global step.\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "    # decay on our learning rate as we progress with training\n",
    "#     TODO: Use step for learn rate\n",
    "    learn_rate = tf.train.exponential_decay(learning_rate, global_step, 1000, 0.8)\n",
    "    tf.scalar_summary('learn rate', learning_rate)\n",
    "    \n",
    "    # Create the gradient Adam optimizer with the given learning rate.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    \n",
    "    # Use the optimizer to apply the gradients that minimize the loss\n",
    "    # (and also increment the global step counter) as a single training step.\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "    return train_op\n",
    "\n",
    "\n",
    "def evaluation(logits, labels):\n",
    "    \"\"\"Evaluate the quality of the logits at predicting the label.\n",
    "    Args:\n",
    "    logits: Logits tensor, float - [batch_size, NUM_CLASSES].\n",
    "    labels: Labels tensor, int32 - [batch_size], with values in the\n",
    "      range [0, NUM_CLASSES).\n",
    "    Returns:\n",
    "    A scalar int32 tensor with the number of examples (out of batch_size)\n",
    "    that were predicted correctly.\n",
    "    \"\"\"\n",
    "    # For a classifier model, we can use the in_top_k Op.\n",
    "    # It returns a bool tensor with shape [batch_size] that is true for\n",
    "    # the examples where the label is in the top k (here k=1)\n",
    "    # of all logits for that example.\n",
    "    correct = tf.nn.in_top_k(logits, labels, 1)\n",
    "    # Return the number of true entries.\n",
    "    return tf.reduce_sum(tf.cast(correct, tf.int32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Graph().as_default():\n",
    "        \n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        \n",
    "        images, labels = inputs(True, batch_size, num_epochs)\n",
    "        \n",
    "        logits = inference(images, keep_prob)\n",
    "                \n",
    "        loss_op = loss(logits, labels)\n",
    "        \n",
    "        train_op = training(loss_op, learning_rate)\n",
    "\n",
    "        init_op = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "        sess = tf.Session()\n",
    "        sess.as_default()\n",
    "        \n",
    "        sess.run(init_op)\n",
    "\n",
    "        # Start populating the filename queue.\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        \n",
    "\n",
    "    try:\n",
    "        step = 0\n",
    "        while not coord.should_stop():\n",
    "            start_time = time.time()\n",
    "\n",
    "            _, loss_value = sess.run([train_op, loss_op], feed_dict={keep_prob : 0.5})\n",
    "\n",
    "            duration = time.time() - start_time\n",
    "\n",
    "            # Print an overview fairly often.\n",
    "            if step % 100 == 0:\n",
    "                print('Step %d: loss = %.2f (%.3f sec)' % (step, loss_value, duration))\n",
    "                \n",
    "            elif step % 1000 == 0:\n",
    "                # Save model\n",
    "                \n",
    "            step += 1\n",
    "    \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done training for %d epochs, %d steps.' % (epochs, step))\n",
    "    \n",
    "    finally:\n",
    "        # When done, ask the threads to stop.\n",
    "        coord.request_stop()\n",
    "\n",
    "        \n",
    "    # Wait for threads to finish.\n",
    "    coord.join(threads)\n",
    "    sess.close()\n",
    "        \n",
    "        \n",
    "run_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test_images(path):\n",
    "    \"\"\"Load image to classify\"\"\"\n",
    "    test_images = []\n",
    "    paths = os.path.join(path, '*.jpg')\n",
    "    image_files = glob.glob(paths)\n",
    "    for i in paths:\n",
    "        image = Image.open(i)\n",
    "        test_images.append(image.getdata())\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
