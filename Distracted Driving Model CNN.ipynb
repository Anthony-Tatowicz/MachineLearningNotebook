{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import sys\n",
    "sys.path.append('/models/StateFarmChallenge')\n",
    "import os\n",
    "import logging\n",
    "\n",
    "from six.moves import xrange\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from submission import Submission\n",
    "\n",
    "import math\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to process the data, by scaling an cropping each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/SFC/imgs/train/c0/img_44733.jpg\n",
      "c0\n",
      "[[[-0.43725491]\n",
      "  [-0.43725491]\n",
      "  [-0.43725491]\n",
      "  ..., \n",
      "  [ 0.5       ]\n",
      "  [ 0.49607849]\n",
      "  [ 0.49215692]]\n",
      "\n",
      " [[-0.43725491]\n",
      "  [-0.43725491]\n",
      "  [-0.43725491]\n",
      "  ..., \n",
      "  [ 0.5       ]\n",
      "  [ 0.49607849]\n",
      "  [ 0.49387258]]\n",
      "\n",
      " [[-0.43725491]\n",
      "  [-0.43725491]\n",
      "  [-0.43725491]\n",
      "  ..., \n",
      "  [ 0.49607849]\n",
      "  [ 0.49607849]\n",
      "  [ 0.49607849]]\n",
      "\n",
      " ..., \n",
      " [[-0.31421566]\n",
      "  [-0.36421567]\n",
      "  [-0.41470587]\n",
      "  ..., \n",
      "  [-0.4615196 ]\n",
      "  [-0.45539215]\n",
      "  [-0.4642157 ]]\n",
      "\n",
      " [[-0.44607842]\n",
      "  [-0.22401959]\n",
      "  [-0.09313723]\n",
      "  ..., \n",
      "  [-0.45980391]\n",
      "  [-0.44705883]\n",
      "  [-0.45588234]]\n",
      "\n",
      " [[-0.49313724]\n",
      "  [-0.39289215]\n",
      "  [-0.17941174]\n",
      "  ..., \n",
      "  [-0.45514706]\n",
      "  [-0.43186274]\n",
      "  [-0.38774508]]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Field 1 in record 0 is not a valid int32: c0\n\t [[Node: input/DecodeCSV = DecodeCSV[OUT_TYPE=[DT_STRING, DT_INT32, DT_STRING], field_delim=\",\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input/ReaderRead:1, input/DecodeCSV/record_defaults_0, input/DecodeCSV/record_defaults_1, input/DecodeCSV/record_defaults_2)]]\nCaused by op u'input/DecodeCSV', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2831, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-60-21f2a37b07d2>\", line 253, in <module>\n    run_training()\n  File \"<ipython-input-60-21f2a37b07d2>\", line 218, in run_training\n    images, labels = inputs(batch_size, num_epochs)\n  File \"<ipython-input-60-21f2a37b07d2>\", line 184, in inputs\n    image, label = decode_and_process_img(file_queue)\n  File \"<ipython-input-60-21f2a37b07d2>\", line 167, in decode_and_process_img\n    subject, label, img_file = tf.decode_csv(value, record_defaults=record_defaults)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_parsing_ops.py\", line 38, in decode_csv\n    field_delim=field_delim, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-21f2a37b07d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m \u001b[0mrun_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-60-21f2a37b07d2>\u001b[0m in \u001b[0;36mrun_training\u001b[1;34m()\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[0mcoord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m         \u001b[0mcoord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.pyc\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, threads, stop_grace_period_secs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m         \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mstragglers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         raise RuntimeError(\"Coordinator stopped with threads still running: %s\",\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, sess, enqueue_op, coord)\u001b[0m\n\u001b[0;32m    183\u001b[0m           \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m           \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menqueue_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m           \u001b[1;31m# This exception indicates that a queue was closed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 340\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    341\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 564\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    565\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m       \u001b[1;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 637\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    638\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    657\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m       raise errors._make_specific_exception(node_def, op, error_message,\n\u001b[1;32m--> 659\u001b[1;33m                                             e.code)\n\u001b[0m\u001b[0;32m    660\u001b[0m       \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Field 1 in record 0 is not a valid int32: c0\n\t [[Node: input/DecodeCSV = DecodeCSV[OUT_TYPE=[DT_STRING, DT_INT32, DT_STRING], field_delim=\",\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input/ReaderRead:1, input/DecodeCSV/record_defaults_0, input/DecodeCSV/record_defaults_1, input/DecodeCSV/record_defaults_2)]]\nCaused by op u'input/DecodeCSV', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2831, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-60-21f2a37b07d2>\", line 253, in <module>\n    run_training()\n  File \"<ipython-input-60-21f2a37b07d2>\", line 218, in run_training\n    images, labels = inputs(batch_size, num_epochs)\n  File \"<ipython-input-60-21f2a37b07d2>\", line 184, in inputs\n    image, label = decode_and_process_img(file_queue)\n  File \"<ipython-input-60-21f2a37b07d2>\", line 167, in decode_and_process_img\n    subject, label, img_file = tf.decode_csv(value, record_defaults=record_defaults)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_parsing_ops.py\", line 38, in decode_csv\n    field_delim=field_delim, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "DATA_FILE_PATH = '/data/SFC/driver_imgs_list.csv'\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "batch_size = 128\n",
    "patch_size = 10\n",
    "depth1 = 32\n",
    "depth2 = 64\n",
    "depth3 = 64\n",
    "num_hidden = 512\n",
    "learning_rate = .01\n",
    "num_channels = 1\n",
    "image_size = 256 * 256\n",
    "num_epochs = 2\n",
    "beta = .01\n",
    "\n",
    "\n",
    "def inference(images, keep_prob):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    images: Images placeholder, from inputs().\n",
    "    Returns:\n",
    "    softmax_linear: Output tensor with the computed logits.\n",
    "    \"\"\"\n",
    "\n",
    "#     Conv1 /w pooling\n",
    "    with tf.name_scope('conv1') as scope:\n",
    "        weights = tf.Variable(tf.truncated_normal(\n",
    "              [patch_size, patch_size, num_channels, depth1], stddev=0.01))\n",
    "        biases = tf.Variable(tf.zeros([depth1]))\n",
    "        conv = tf.nn.conv2d(images, weights, [1, 1, 1 ,1], padding='SAME', name='conv1')\n",
    "        conv1 = tf.nn.relu(conv, name=scope)\n",
    "        \n",
    "    pool1 = tf.nn.avg_pool(conv1, [1, 6, 6, 1], [1, 2, 2, 1], padding='SAME', name='pool1')\n",
    "    norm1 = tf.nn.local_response_normalization(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n",
    "\n",
    "#     Conv2 /w pooling \n",
    "    with tf.name_scope('conv2') as scope:\n",
    "        weights = tf.Variable(tf.truncated_normal(\n",
    "              [patch_size, patch_size, depth1, depth2], stddev=0.01))\n",
    "        biases = tf.Variable(tf.constant(1.0, shape=[depth2]))\n",
    "        conv = tf.nn.conv2d(norm1, weights, [1, 1, 1, 1], padding='SAME', name='conv2')\n",
    "        conv2 = tf.nn.relu(conv, name=scope)\n",
    "    \n",
    "    pool2 = tf.nn.avg_pool(conv2, [1, 6, 6, 1], [1, 2, 2, 1], padding='SAME', name='pool2')\n",
    "    norm2 = tf.nn.local_response_normalization(pool2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm2')\n",
    "    \n",
    "#     Conv3 /w pooling\n",
    "    with tf.name_scope('conv3') as scope:\n",
    "        weights = tf.Variable(tf.truncated_normal(\n",
    "              [patch_size, patch_size, depth2, depth3], stddev=0.01))\n",
    "        biases = tf.Variable(tf.constant(1.0, shape=[depth3]))\n",
    "        conv = tf.nn.conv2d(norm2, weights, [1, 1, 1, 1], padding='SAME', name='conv3')\n",
    "        conv3 = tf.nn.relu(conv, name=scope)\n",
    "    \n",
    "    pool3 = tf.nn.avg_pool(conv3, [1, 6, 6, 1], [1, 2, 2, 1], padding='SAME', name='pool3')\n",
    "    norm3 = tf.nn.local_response_normalization(pool3, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm3') \n",
    "    shape = norm3.get_shape().as_list()\n",
    "    reshape = tf.reshape(norm3, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "        \n",
    "        \n",
    "#     local4\n",
    "    with tf.name_scope('local3') as scope:\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([image_size, num_hidden],\n",
    "                                stddev=1.0 / math.sqrt(float(num_hidden))))\n",
    "\n",
    "        biases = tf.Variable(tf.zeros([num_hidden]))\n",
    "        z = tf.matmul(reshape, weights) + biases\n",
    "        local4 = tf.nn.relu(z, name=scope)\n",
    "\n",
    "#     local5\n",
    "    with tf.name_scope('local4') as scope:\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([num_hidden, num_hidden],\n",
    "                                stddev=1.0 / math.sqrt(float(num_hidden))), name='weights_5')\n",
    "\n",
    "        biases = tf.Variable(tf.zeros([num_hidden]),name='biases_5')\n",
    "        z = tf.matmul(local4, weights) + biases\n",
    "        local5 = tf.nn.relu(z, name=scope)\n",
    "        drop = tf.nn.dropout(local5, keep_prob)\n",
    "        \n",
    "        \n",
    "    # Linear\n",
    "    with tf.name_scope('softmax_linear'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([num_hidden, NUM_CLASSES],\n",
    "                                stddev=1.0 / math.sqrt(float(num_hidden))), name='weights_s')\n",
    "\n",
    "        biases = tf.Variable(tf.zeros([NUM_CLASSES]), name='biases_s')\n",
    "        logits = tf.matmul(drop, weights) + biases\n",
    "        \n",
    "    return logits\n",
    "\n",
    "\n",
    "def loss(logits, labels):\n",
    "    \"\"\"\"\n",
    "    Calculates the loss from the logits and the labels.\n",
    "    Args:\n",
    "    logits: Logits tensor, float - [batch_size, NUM_CLASSES].\n",
    "    labels: Labels tensor, int64 - [batch_size].\n",
    "    Returns:\n",
    "    loss: Loss tensor of type float.\n",
    "    \"\"\"\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels, name='xentropy')\n",
    "    loss = tf.reduce_mean(cross_entropy, name='xentropy_mean')\n",
    "    loss_prime = loss + beta * tf.nn.l2_loss(logits)\n",
    "    return loss_prime\n",
    "\n",
    "\n",
    "def training(loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Sets up the training Ops.\n",
    "    Creates a summarizer to track the loss over time in TensorBoard.\n",
    "    Creates an optimizer and applies the gradients to all trainable variables.\n",
    "    The Op returned by this function is what must be passed to the\n",
    "    `sess.run()` call to cause the model to train.\n",
    "    Args:\n",
    "    loss: Loss tensor, from loss().\n",
    "    learning_rate: The learning rate to use for gradient descent.\n",
    "    Returns:\n",
    "    train_op: The Op for training.\n",
    "    \"\"\"\n",
    "    # Add a scalar summary for the snapshot loss. (Tensor board)\n",
    "    tf.scalar_summary('loss', loss)\n",
    "\n",
    "    # Create a variable to track the global step.\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "    # decay on our learning rate as we progress with training\n",
    "    learn_rate = tf.train.exponential_decay(learning_rate, global_step, 1000, 0.8)\n",
    "    tf.scalar_summary('learn_rate', learning_rate)\n",
    "    \n",
    "    # Create the gradient Adam optimizer with the given learning rate.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    \n",
    "    # Use the optimizer to apply the gradients that minimize the loss\n",
    "    # (and also increment the global step counter) as a single training step.\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "    return train_op\n",
    "\n",
    "\n",
    "def evaluation(logits, labels):\n",
    "    \"\"\"Evaluate the quality of the logits at predicting the label.\n",
    "    Args:\n",
    "    logits: Logits tensor, float - [batch_size, NUM_CLASSES].\n",
    "    labels: Labels tensor, int32 - [batch_size], with values in the\n",
    "      range [0, NUM_CLASSES).\n",
    "    Returns:\n",
    "    A scalar int32 tensor with the number of examples (out of batch_size)\n",
    "    that were predicted correctly.\n",
    "    \"\"\"\n",
    "    # For a classifier model, we can use the in_top_k Op.\n",
    "    # It returns a bool tensor with shape [batch_size] that is true for\n",
    "    # the examples where the label is in the top k (here k=1)\n",
    "    # of all logits for that example.\n",
    "    correct = tf.nn.in_top_k(logits, labels, 1)\n",
    "    # Return the number of true entries.\n",
    "    return tf.reduce_sum(tf.cast(correct, tf.int32))\n",
    "\n",
    "\n",
    "\n",
    "def decode_and_process_img(queue):\n",
    "    # Reader to read csv rows\n",
    "    reader = tf.TextLineReader()\n",
    "    key, value = reader.read(queue)\n",
    "    \n",
    "    record_defaults = [[''], [''], ['']]\n",
    "    subject, label, img_file = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "    \n",
    "    path = tf.cast('/data/SFC/imgs/train/' + label + '/' + img_file, tf.string)\n",
    "    img_file = tf.read_file(path)\n",
    "    img_data = tf.image.decode_jpeg(img_file, channels=1)\n",
    "    resized = tf.image.resize_images(img_data, 256, 256)\n",
    "#    scaled_croped = tf.image.crop_to_bounding_box(scaled, 0, 43, 256, 256)\n",
    "\n",
    "    # Convert from [0, 255] -> [-0.5, 0.5] floats.\n",
    "    image = tf.cast(resized, tf.float32) * (1. / 255) - 0.5\n",
    "\n",
    "    return image, label\n",
    "\n",
    "    \n",
    "def inputs(batch_size, num_epochs):\n",
    "    with tf.name_scope('input'):\n",
    "        # Create queue for csv file\n",
    "        file_queue = tf.train.string_input_producer([DATA_FILE_PATH], num_epochs=num_epochs)\n",
    "\n",
    "        image, label = decode_and_process_img(file_queue)\n",
    "        \n",
    "        images, labels = tf.train.shuffle_batch([image, label], batch_size=batch_size, \n",
    "                                                num_threads=2,\n",
    "                                                capacity=1000 + 3 * batch_size,\n",
    "                                                min_after_dequeue=1000)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def run_training():\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Graph().as_default():\n",
    "        \n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        \n",
    "        images, labels = inputs(batch_size, num_epochs)\n",
    "        \n",
    "        logits = inference(images, keep_prob)\n",
    "                \n",
    "        loss_op = loss(logits, labels)\n",
    "        \n",
    "        train_op = training(loss_op, learning_rate)\n",
    "\n",
    "        init_op = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "        sess = tf.Session()\n",
    "        sess.as_default()\n",
    "        \n",
    "        sess.run(init_op)\n",
    "\n",
    "        # Start populating the filename queue.\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        \n",
    "        print(path.eval(session=sess))\n",
    "        print(label.eval(session=sess))\n",
    "        print(image.eval(session=sess))\n",
    "        \n",
    "#         for i in range(1):\n",
    "#             # Retrieve a single instance:\n",
    "#             _, ls = sess.run([train_op, loss_op], feed_dict={keep_prob : 0.5})\n",
    "#             print(ls)\n",
    "#             print(len(labels))\n",
    "\n",
    "\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        sess.close()\n",
    "        \n",
    "run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
