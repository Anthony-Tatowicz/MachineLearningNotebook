{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import math\n",
    "\n",
    "from six.moves import xrange\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import Image\n",
    "\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "DATA_PATH = '../data/statefarmchallenge/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to recoreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading csv\n",
      "Generating validation record\n",
      "Loading batch\n",
      "Writing ../data/statefarmchallenge/validation.tfrecords\n",
      "Loading batch\n",
      "Writing ../data/statefarmchallenge/validation.tfrecords\n",
      "Loading batch\n",
      "Writing ../data/statefarmchallenge/validation.tfrecords\n",
      "Loading batch\n",
      "Writing ../data/statefarmchallenge/validation.tfrecords\n",
      "Loading batch\n",
      "Writing ../data/statefarmchallenge/validation.tfrecords\n",
      "Loading batch\n",
      "Writing ../data/statefarmchallenge/validation.tfrecords\n",
      "Generating train record\n",
      "Loading batch\n"
     ]
    }
   ],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _byte_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def convert(images, labels, name):\n",
    "    \"\"\"Convert images and labesl to TFRecord\"\"\"\n",
    "    num_examples = labels.shape[0]\n",
    "    if images.shape[0] != num_examples:\n",
    "        raise ValueError(\"images size {} did not match labels size {}\"\n",
    "                         .format(images.shape[0], num_examples))\n",
    "        \n",
    "    rows = images.shape[1]\n",
    "    cols = images.shape[2]\n",
    "    depth = images.shape[3]\n",
    "\n",
    "    filename = os.path.join(DATA_PATH, name + '.tfrecords')\n",
    "    print('Writing', filename)\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    for index in range(num_examples):\n",
    "        image_raw = images[index].tostring()\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'height': _int64_feature(rows),\n",
    "            'width': _int64_feature(cols),\n",
    "            'depth': _int64_feature(depth),\n",
    "            'label': _int64_feature(labels[index]),\n",
    "            'image_raw': _byte_feature(image_raw)}))\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()\n",
    "       \n",
    "\n",
    "def load_image(infilename):\n",
    "    \"\"\"Load our image and return as numpy array\"\"\"\n",
    "    img = Image.open(infilename)\n",
    "    data = np.asarray(img)\n",
    "    return data\n",
    "\n",
    "\n",
    "def load(rows, data_path):\n",
    "    \"\"\"Load a batch of images & labels for converting\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    print('Loading batch')\n",
    "    for row in rows:\n",
    "        path = os.path.join(data_path, row[1], row[2])\n",
    "        data = load_image(path)\n",
    "        images.append(data)\n",
    "        labels.append(int(row[1][1]))\n",
    "    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "\n",
    "\n",
    "def gen_record(size, records, name, num_batches, data_path):\n",
    "    \"\"\"Generate a record file by batching data\"\"\"\n",
    "    examples_per_batch = size // num_batches\n",
    "    \n",
    "    if examples_per_batch <= 1:\n",
    "        raise ValueError('Batch size must be greater than 1')\n",
    "        \n",
    "    print(\"Generating \" + name + \" record\")\n",
    "    for i in xrange(num_batches):\n",
    "        k = i * examples_per_batch\n",
    "        record_b = records[k : k + examples_per_batch]\n",
    "\n",
    "        images_b, labels_b = load(record_b, data_path)\n",
    "\n",
    "        convert(images_b, labels_b, name)\n",
    "                \n",
    "    # What about left overs???\n",
    "    records_processed = examples_per_batch * num_batches\n",
    "    left_over = size - records_processed\n",
    "    \n",
    "    if left_over > 0:\n",
    "        record_b = records[records_processed:]\n",
    "        images_b, labels_b = load(record_b, data_path)\n",
    "        convert(images_b, labels_b, name)\n",
    "        \n",
    "        \n",
    "\n",
    "def read_csv(path):\n",
    "    \"\"\"Read CSV record and return as list\"\"\"\n",
    "    print('Reading csv')\n",
    "                \n",
    "    with open(path, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        records = list(reader)\n",
    "    \n",
    "    return records\n",
    "        \n",
    "\n",
    "    \n",
    "def main(argv):\n",
    "    records = read_csv(DATA_PATH + 'driver_imgs_list.csv')\n",
    "    num_examples = len(records)\n",
    "    \n",
    "    # Generate validation TFRecords (20%)\n",
    "    validation_size = num_examples // 5\n",
    "    val_records = records[ : validation_size]\n",
    "    gen_record(size=validation_size, \n",
    "               records=val_records, \n",
    "               name='validation', \n",
    "               num_batches=5, \n",
    "               data_path=DATA_PATH + 'imgs/train/')\n",
    "\n",
    "    \n",
    "    # Generate training TFRecords\n",
    "    train_size = num_examples - validation_size\n",
    "    train_records = records[validation_size : ]\n",
    "    gen_record(size=train_size, \n",
    "               records=train_records, \n",
    "               name='train', \n",
    "               num_batches=10, \n",
    "               data_path=DATA_PATH + 'imgs/train')\n",
    "                \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "# Convolution output depths \n",
    "depth_1 = 16\n",
    "depth_2 = 64\n",
    "depth_3 = 256\n",
    "\n",
    "# shapes\n",
    "channels = 3\n",
    "\n",
    "# Local layer size\n",
    "num_hidden = 2048\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = .01\n",
    "decay_rate = .9\n",
    "decay_setps = 1000\n",
    "\n",
    "# Regularization\n",
    "beta = 1e-3\n",
    "\n",
    "# batching and images size\n",
    "batch_size = 256\n",
    "epochs = 2\n",
    "height = 480\n",
    "width = 640\n",
    "depth = 3\n",
    "image_size = height * width * depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline queues up file names decodes and preprocess images and then shuffles them.  \n",
    "\n",
    "**NOTE** Try using parse_example for batching and skip post batching/shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_FILE = 'train.tfrecords'\n",
    "VALIDATION_FILE = 'validation.tfrecords'\n",
    "    \n",
    "def read_and_decode(filename_queue):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(\n",
    "      serialized_example,\n",
    "      # Defaults are not specified since both keys are required.\n",
    "      features={\n",
    "            'height' : tf.FixedLenFeature([], tf.int64),\n",
    "            'width' : tf.FixedLenFeature([], tf.int64),\n",
    "            'depth' : tf.FixedLenFeature([], tf.int64),\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64),\n",
    "      })\n",
    "\n",
    "    # Convert from a scalar string to unit8 tensor\n",
    "    image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "    image = tf.reshape(image, [height, width, depth])\n",
    "\n",
    "    # OPTIONAL: Could reshape image and apply distortions or whitening here\n",
    "\n",
    "\n",
    "    # Convert from [0, 255] -> [-0.5, 0.5] floats.\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.sub(tf.mul(image, 3.921568e-3), 0.5)\n",
    "\n",
    "    # Convert label from a scalar uint8 tensor to an int32 scalar.\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "\n",
    "    return image, label\n",
    "    \n",
    "def inputs(train, batch_size, num_epochs):\n",
    "    if not num_epochs: num_epochs = None\n",
    "    filename = os.path.join(DATA_PATH, TRAIN_FILE if train else VALIDATION_FILE)\n",
    "\n",
    "    with tf.name_scope('input'):\n",
    "        filename_queue = tf.train.string_input_producer([filename], num_epochs=num_epochs)\n",
    "\n",
    "    # Even when reading in multiple threads, share the filename\n",
    "    # queue.\n",
    "    image, label = read_and_decode(filename_queue)\n",
    "    \n",
    "    # Shuffle the examples and collect them into batch_size batches.\n",
    "    # (Internally uses a RandomShuffleQueue.)\n",
    "    # We run this in 8 threads to avoid being a bottleneck.\n",
    "    images, sparse_labels = tf.train.shuffle_batch(\n",
    "        [image, label], batch_size=batch_size, num_threads=8,\n",
    "        capacity=1000 + 3 * batch_size,\n",
    "        # Ensures a minimum amount of shuffling of examples.\n",
    "        min_after_dequeue=1000)\n",
    "\n",
    "    return images, sparse_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _dense_to_one_hot(labels_dense, num_classes):\n",
    "    \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "def _variabel_on_cpu(name, shape, initializer, regularizer=None):\n",
    "    \"\"\"Helper to create a Variable stored on CPU memory.\"\"\"\n",
    "    with tf.device('\\cpu:0'):\n",
    "        var = tf.get_variable(name, shape, initializer=initializer, regularizer=regularizer)\n",
    "    \n",
    "    return var\n",
    "\n",
    "def local_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n",
    "    \"\"\"Reusable code for making a simple neural net layer.\n",
    "\n",
    "    It does a matrix multiply, bias add, and then uses relu to nonlinearize.\n",
    "    It also sets up name scoping so that the resultant graph is easy to read,\n",
    "    and adds a number of summary ops.\n",
    "    \"\"\"\n",
    "    # Adding a name scope ensures logical grouping of the layers in the graph.\n",
    "    with tf.name_scope(layer_name):\n",
    "        # This Variable will hold the state of the weights for the layer\n",
    "        weights = _variable_on_cpu(\"weights\", [input_dim, output_dim],\n",
    "            tf.truncated_normal_initializer(stddev=2.0 / float(input_dim)), \n",
    "            regularizer=tf.contrib.layers.l2_regularizer(beta))\n",
    "        \n",
    "        biases = _variable_on_cpu(\"biases\", [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "        \n",
    "        preactivate = tf.add(tf.matmul(input_tensor, weights), biases)\n",
    "        tf.histogram_summary(layer_name + '/pre_activations', preactivate)\n",
    "            \n",
    "    activations = act(preactivate, 'activation')\n",
    "    tf.histogram_summary(layer_name + '/activations', activations)\n",
    "    return activations\n",
    "\n",
    "def conv_relu(input, kernel_shape, bias_shape, layer_name):\n",
    "    \"\"\"Reusable code for convoltional layers\n",
    "    \n",
    "    It odes the 2D convolution and relu\n",
    "    \"\"\"\n",
    "    with tf.name_scope(layer_name):\n",
    "        # Create variable named \"weights\".\n",
    "        weights = _variabel_on_cpu(\"weights\", kernel_shape,\n",
    "            initializer=tf.truncated_normal_initializer(stddev=1e-4),\n",
    "            regularizer=tf.contrib.layers.l2_regularizer(beta))\n",
    "\n",
    "        # Create variable named \"biases\".\n",
    "        biases = _variabel_on_cpu(\"biases\", [bias_shape], initializer=tf.constant_initializer(0.0))\n",
    "        conv = tf.nn.conv2d(input, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(tf.add(conv, biases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO:*\n",
    "- ~~Add variable reuse~~\n",
    "- ~~add images to summary~~\n",
    "- ~~change learning rate to exp step~~\n",
    "- Test tensorboard\n",
    "- ~~clean up local layers~~\n",
    "- ~~update local initialization~~\n",
    "- consider 1x1 convolutions\n",
    "- and insception ie. pool --> 1x1 conv --> 1x1, 3x3, 5x5 --> concat all outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inference(images, keep_prob):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    images: Images placeholder, from inputs().\n",
    "    Returns:\n",
    "    softmax_linear: Output tensor with the computed logits.\n",
    "    \"\"\"\n",
    "\n",
    "    # Conv1 /w pooling\n",
    "    conv_1 = conv_relu(images, [5, 5, channels, depth_1], [depth_1], 'conv_1')     \n",
    "    pool_1 = tf.nn.avg_pool(conv_1, [1, 6, 6, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    norm_1 = tf.nn.local_response_normalization(pool_1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "        \n",
    "    # Conv2 /w pooling \n",
    "    conv_2 = conv_relu(norm_1, [3, 3, depth_1, depth_2], [depth_2], 'conv_2')     \n",
    "    pool_2 = tf.nn.avg_pool(conv_2, [1, 6, 6, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    norm_2 = tf.nn.local_response_normalization(pool_2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "\n",
    "    # Conv3 /w pooling\n",
    "    conv_3 = conv_relu(norm_2, [3, 3, depth_2, depth_3], [depth_3], 'conv_3')     \n",
    "    pool_3 = tf.nn.avg_pool(conv_3, [1, 6, 6, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    norm_3 = tf.nn.local_response_normalization(pool_3, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    \n",
    "    shape = norm_3.get_shape().as_list()\n",
    "    dim = tf.mul(shape[1], tf.mul(shape[2], shape[3]))\n",
    "    reshape = tf.reshape(norm_3, [shape[0], dim])\n",
    "   \n",
    "    #local4\n",
    "    local_4 = local_layer(reshape, image_size, num_hidden, \"local_4\")\n",
    "    drop = tf.nn.dropout(local_4, keep_prob)\n",
    "\n",
    "    # local5\n",
    "    local_5 = local_layer(drop, num_hidden, num_hidden, \"local_5\")\n",
    "    drop = tf.nn.dropout(local_5, keep_prob)\n",
    "   \n",
    "    # Linear\n",
    "    with tf.name_scope('softmax'):\n",
    "        weights = _variable_on_cpu('weights', [num_hidden, num_classes],\n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=2.0 / float(num_hidden)))\n",
    "\n",
    "        bias = _variable_on_cpu('biases', [num_classes],\n",
    "                               initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "        logits = tf.add(tf.matmul(drop, weights), bias)\n",
    "        \n",
    "    return logits\n",
    "\n",
    "\n",
    "def loss(logits, labels):\n",
    "    \"\"\"\"\n",
    "    Calculates the loss from the logits and the labels.\n",
    "    Args:\n",
    "    logits: Logits tensor, float - [batch_size, NUM_CLASSES].\n",
    "    labels: Labels tensor, int64 - [batch_size].\n",
    "    Returns:\n",
    "    loss: Loss tensor of type float.\n",
    "    \"\"\"\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels, name='xentropy')\n",
    "    loss = tf.reduce_mean(cross_entropy, name='xentropy_mean')\n",
    "    return loss\n",
    "\n",
    "\n",
    "def training(loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Sets up the training Ops.\n",
    "    Creates a summarizer to track the loss over time in TensorBoard.\n",
    "    Creates an optimizer and applies the gradients to all trainable variables.\n",
    "    The Op returned by this function is what must be passed to the\n",
    "    `sess.run()` call to cause the model to train.\n",
    "    Args:\n",
    "    loss: Loss tensor, from loss().\n",
    "    learning_rate: The learning rate to use for gradient descent.\n",
    "    Returns:\n",
    "    train_op: The Op for training.\n",
    "    \"\"\"\n",
    "    # Add a scalar summary for the snapshot loss. (Tensor board)\n",
    "    tf.scalar_summary('/loss', loss)\n",
    "\n",
    "    # Create a variable to track the global step.\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "    # decay on our learning rate as we progress with training\n",
    "    learn_rate = tf.train.exponential_decay(learning_rate, global_step, decay_steps, decay_rate, staircase=True)\n",
    "    tf.scalar_summary('/learn_rate', learning_rate)\n",
    "    \n",
    "    # Create the gradient Adam optimizer with the given learning rate.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    \n",
    "    # Use the optimizer to apply the gradients that minimize the loss\n",
    "    # (and also increment the global step counter) as a single training step.\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "    return train_op\n",
    "\n",
    "\n",
    "def evaluation(logits, labels):\n",
    "    \"\"\"Evaluate the quality of the logits at predicting the label.\n",
    "    Args:\n",
    "    logits: Logits tensor, float - [batch_size, NUM_CLASSES].\n",
    "    labels: Labels tensor, int32 - [batch_size], with values in the\n",
    "      range [0, NUM_CLASSES).\n",
    "    Returns:\n",
    "    A scalar int32 tensor with the number of examples (out of batch_size)\n",
    "    that were predicted correctly.\n",
    "    \"\"\"\n",
    "    # For a classifier model, we can use the in_top_k Op.\n",
    "    # It returns a bool tensor with shape [batch_size] that is true for\n",
    "    # the examples where the label is in the top k (here k=1)\n",
    "    # of all logits for that example.\n",
    "    correct = tf.nn.in_top_k(logits, labels, 1)\n",
    "    # Return the number of true entries.\n",
    "    return tf.reduce_sum(tf.cast(correct, tf.int32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown attribute: '\\cpu0' in '\\cpu0:'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-a63ff180c204>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m \u001b[0mrun_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-36-a63ff180c204>\u001b[0m in \u001b[0;36mrun_training\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mloss_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-b021a07103de>\u001b[0m in \u001b[0;36minference\u001b[1;34m(images, keep_prob)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Conv1 /w pooling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mconv_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdepth_1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'conv_1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mpool_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavg_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SAME'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mnorm_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_response_normalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m9.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.75\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-0736d0341d2e>\u001b[0m in \u001b[0;36mconv_relu\u001b[1;34m(input, kernel_shape, bias_shape, layer_name)\u001b[0m\n\u001b[0;32m     46\u001b[0m         weights = _variabel_on_cpu(\"weights\", kernel_shape,\n\u001b[0;32m     47\u001b[0m             \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruncated_normal_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstddev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             regularizer=tf.contrib.layers.l2_regularizer(beta))\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# Create variable named \"biases\".\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-0736d0341d2e>\u001b[0m in \u001b[0;36m_variabel_on_cpu\u001b[1;34m(name, shape, initializer, regularizer)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_variabel_on_cpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;34m\"\"\"Helper to create a Variable stored on CPU memory.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\cpu0:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/contextlib.pyc\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mdevice\u001b[1;34m(self, device_name_or_function)\u001b[0m\n\u001b[0;32m   2905\u001b[0m     if (device_name_or_function is not None\n\u001b[0;32m   2906\u001b[0m         and not callable(device_name_or_function)):\n\u001b[1;32m-> 2907\u001b[1;33m       \u001b[0mdevice_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_name_or_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2908\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2909\u001b[0m       \u001b[0mdevice_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice_name_or_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/device.pyc\u001b[0m in \u001b[0;36mmerge_device\u001b[1;34m(spec)\u001b[0m\n\u001b[0;32m    279\u001b[0m   \"\"\"\n\u001b[0;32m    280\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeviceSpec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m     \u001b[0mspec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDeviceSpec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_device_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[0mcurrent_device\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDeviceSpec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/device.pyc\u001b[0m in \u001b[0;36mfrom_string\u001b[1;34m(spec)\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mDeviceSpec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \"\"\"\n\u001b[1;32m--> 227\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mDeviceSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_from_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/device.pyc\u001b[0m in \u001b[0;36mparse_from_string\u001b[1;34m(self, spec)\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mly\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=g-explicit-bool-comparison\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown attribute: '%s' in '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown attribute: '\\cpu0' in '\\cpu0:'"
     ]
    }
   ],
   "source": [
    "def run_training():\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Graph().as_default():\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        \n",
    "        images, labels = inputs(True, batch_size, epochs)\n",
    "        \n",
    "        logits = inference(images, keep_prob)\n",
    "                \n",
    "        loss_op = loss(logits, labels)\n",
    "        \n",
    "        train_op = training(loss_op, learning_rate)\n",
    "        \n",
    "        merge_op = tf.merge_all_summaries()\n",
    "        \n",
    "        eval_op = evaluation(logits, labels)\n",
    "\n",
    "        init_op = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "        sess = tf.Session()\n",
    "        sess.as_default()\n",
    "        \n",
    "        sess.run(init_op)\n",
    "        \n",
    "        writer = tf.train.SummaryWriter('logs/statefarmchallenge', sess.graph)\n",
    "\n",
    "        # Start populating the filename queue.\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        \n",
    "\n",
    "    try:\n",
    "        step = 0\n",
    "        \n",
    "        # Add image summary for the image viewer\n",
    "        tf.image_summary('/images', images)\n",
    "        \n",
    "        while not coord.should_stop():\n",
    "\n",
    "            start_time = time.time()\n",
    "            _, loss = sess.run([train_op, loss_op], feed_dict={keep_prob : 0.5})\n",
    "            duration = time.time() - start_time \n",
    "\n",
    "            # Print some performance info (only for debug)\n",
    "            if step % 10 == 0:\n",
    "                examples_per_second = batch_size / duration\n",
    "                sec_per_batch = float(duration)\n",
    "                \n",
    "                format_str = ('step %d, loss = %.2f (%.1f examples/sec; %.3f sec/batch)')\n",
    "                print (format_str % (step, loss_value, examples_per_sec, sec_per_batch))\n",
    "                \n",
    "            # Write summeries, this is the important visuals for model debugging\n",
    "            if step % 100 == 0:\n",
    "                summary = sess.run(merge_op)\n",
    "                # implment this for model reloading. (will do later)\n",
    "                # global_step = tf.get_variable(name='global_step', trainable=False)\n",
    "                tf.train.SummaryWriter.add_summary(summary, step)\n",
    "                \n",
    "            # Save & validate the model perodically\n",
    "            # if step % 1000 == 0:\n",
    "                # TODO: Validation\n",
    "                \n",
    "            step += 1\n",
    "    \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done training for %d epochs, %d steps.' % (epochs, step))\n",
    "    \n",
    "    finally:\n",
    "        # When done, ask the threads to stop.\n",
    "        coord.request_stop()\n",
    "\n",
    "        \n",
    "    # Wait for threads to finish.\n",
    "    coord.join(threads)\n",
    "    sess.close()\n",
    "        \n",
    "        \n",
    "run_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "- Convert test images to TF records\n",
    "- Use pipeline to feed images for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test_images(path):\n",
    "    \"\"\"Load image to classify\"\"\"\n",
    "    test_images = []\n",
    "    paths = os.path.join(path, '*.jpg')\n",
    "    image_files = glob.glob(paths)\n",
    "    for i in paths:\n",
    "        image = Image.open(i)\n",
    "        test_images.append(image.getdata())\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
