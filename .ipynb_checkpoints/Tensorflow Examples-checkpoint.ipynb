{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Numerical Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % [ 0.18837291] [ 0.36170402]\n",
      "10.0 % [ 0.10923819] [ 0.29469073]\n",
      "20.0 % [ 0.10214574] [ 0.29876685]\n",
      "30.0 % [ 0.10049839] [ 0.29971358]\n",
      "40.0 % [ 0.10011576] [ 0.29993349]\n",
      "50.0 % [ 0.10002688] [ 0.29998457]\n",
      "60.0 % [ 0.10000625] [ 0.29999644]\n",
      "70.0 % [ 0.10000145] [ 0.29999918]\n",
      "80.0 % [ 0.10000034] [ 0.2999998]\n",
      "90.0 % [ 0.1000001] [ 0.29999995]\n",
      "100.0 % [ 0.1000001] [ 0.29999995]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Create 100 phony x, y data points in NumPy, y = x * 0.1 + 0.3\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "\n",
    "# Try to find values for W and b that compute y_data = W * x_data + b\n",
    "# (We know that W should be 0.1 and b 0.3, but Tensorflow will\n",
    "# figure that out for us.)\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "y = W * x_data + b\n",
    "\n",
    "# Minimize the mean squared errors.\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# Before starting, initialize the variables.  We will 'run' this first.\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph.\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Fit the line.\n",
    "for step in range(201):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print((step / 200) * 100, \"%\", sess.run(W), sess.run(b))\n",
    "        \n",
    "sess.close()\n",
    "\n",
    "# Learns best fit is W: [0.1], b: [0.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12]]\n",
      "[[12]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "matrix1 = tf.constant([[3, 3]])\n",
    "matrix2 = tf.constant([[2], [2]])\n",
    "\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "sess = tf.Session()\n",
    "result = sess.run(product)\n",
    "\n",
    "print(result)\n",
    "sess.close()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run(product)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2. -1.]\n"
     ]
    }
   ],
   "source": [
    "# Enter an interactive TensorFlow Session.\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "x = tf.Variable([1.0, 2.0])\n",
    "a = tf.constant([3.0, 3.0])\n",
    "\n",
    "# Initialize 'x' using the run() method of its initializer op.\n",
    "x.initializer.run()\n",
    "\n",
    "# Add an op to subtract 'a' from 'x'.  Run it and print the result\n",
    "sub = tf.sub(x, a)\n",
    "print(sub.eval())\n",
    "# ==> [-2. -1.]\n",
    "\n",
    "# Close the Session when we're done.\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Create a Variable, that will be initialized to the scalar value 0.\n",
    "state = tf.Variable(0, name=\"counter\")\n",
    "\n",
    "# Create an Op to add one to `state`.\n",
    "\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)\n",
    "\n",
    "# Variables must be initialized by running an `init` Op after having\n",
    "# launched the graph.  We first have to add the `init` Op to the graph.\n",
    "init_op = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph and run the ops.\n",
    "with tf.Session() as sess:\n",
    "  # Run the 'init' op\n",
    "  sess.run(init_op)\n",
    "  # Print the initial value of 'state'\n",
    "  print(sess.run(state))\n",
    "  # Run the op that updates 'state' and print 'state'.\n",
    "  for _ in range(3):\n",
    "    sess.run(update)\n",
    "    print(sess.run(state))\n",
    "\n",
    "# output:\n",
    "\n",
    "# 0\n",
    "# 1\n",
    "# 2\n",
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.constant(3.0)\n",
    "input2 = tf.constant(2.0)\n",
    "input3 = tf.constant(5.0)\n",
    "intermed = tf.add(input2, input3)\n",
    "mul = tf.mul(input1, intermed)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  result = sess.run([mul, intermed])\n",
    "  print(result)\n",
    "\n",
    "# output:\n",
    "# [array([ 21.], dtype=float32), array([ 7.], dtype=float32)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeds\n",
    "\n",
    "The examples above introduce tensors into the computation graph by storing them in Constants and Variables. TensorFlow also provides a feed mechanism for patching a tensor directly into any operation in the graph.\n",
    "\n",
    "A feed temporarily replaces the output of an operation with a tensor value. You supply feed data as an argument to a run() call. The feed is only used for the run call to which it is passed. The most common use case involves designating specific operations to be \"feed\" operations by using tf.placeholder() to create them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 14.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "output = tf.mul(input1, input2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  print(sess.run([output], feed_dict={input1:[7.], input2:[2.]}))\n",
    "\n",
    "# output:\n",
    "# [array([ 14.], dtype=float32)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## k-means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from random import choice, shuffle\n",
    "from numpy import array\n",
    " \n",
    " \n",
    "def TFKMeansCluster(vectors, noofclusters):\n",
    "    \"\"\"\n",
    "    K-Means Clustering using TensorFlow.\n",
    "    'vectors' should be a n*k 2-D NumPy array, where n is the number\n",
    "    of vectors of dimensionality k.\n",
    "    'noofclusters' should be an integer.\n",
    "    \"\"\"\n",
    " \n",
    "    noofclusters = int(noofclusters)\n",
    "    assert noofclusters < len(vectors)\n",
    " \n",
    "    #Find out the dimensionality\n",
    "    dim = len(vectors[0])\n",
    " \n",
    "    #Will help select random centroids from among the available vectors\n",
    "    vector_indices = list(range(len(vectors)))\n",
    "    shuffle(vector_indices)\n",
    " \n",
    "    #GRAPH OF COMPUTATION\n",
    "    #We initialize a new graph and set it as the default during each run\n",
    "    #of this algorithm. This ensures that as this function is called\n",
    "    #multiple times, the default graph doesn't keep getting crowded with\n",
    "    #unused ops and Variables from previous function calls.\n",
    " \n",
    "    graph = tf.Graph()\n",
    " \n",
    "    with graph.as_default():\n",
    " \n",
    "        #SESSION OF COMPUTATION\n",
    " \n",
    "        sess = tf.Session()\n",
    " \n",
    "        ##CONSTRUCTING THE ELEMENTS OF COMPUTATION\n",
    " \n",
    "        ##First lets ensure we have a Variable vector for each centroid,\n",
    "        ##initialized to one of the vectors from the available data points\n",
    "        centroids = [tf.Variable((vectors[vector_indices[i]]))\n",
    "                     for i in range(noofclusters)]\n",
    "        ##These nodes will assign the centroid Variables the appropriate\n",
    "        ##values\n",
    "        centroid_value = tf.placeholder(\"float64\", [dim])\n",
    "        cent_assigns = []\n",
    "        for centroid in centroids:\n",
    "            cent_assigns.append(tf.assign(centroid, centroid_value))\n",
    " \n",
    "        ##Variables for cluster assignments of individual vectors(initialized\n",
    "        ##to 0 at first)\n",
    "        assignments = [tf.Variable(0) for i in range(len(vectors))]\n",
    "        ##These nodes will assign an assignment Variable the appropriate\n",
    "        ##value\n",
    "        assignment_value = tf.placeholder(\"int32\")\n",
    "        cluster_assigns = []\n",
    "        for assignment in assignments:\n",
    "            cluster_assigns.append(tf.assign(assignment,\n",
    "                                             assignment_value))\n",
    " \n",
    "        ##Now lets construct the node that will compute the mean\n",
    "        #The placeholder for the input\n",
    "        mean_input = tf.placeholder(\"float\", [None, dim])\n",
    "        #The Node/op takes the input and computes a mean along the 0th\n",
    "        #dimension, i.e. the list of input vectors\n",
    "        mean_op = tf.reduce_mean(mean_input, 0)\n",
    " \n",
    "        ##Node for computing Euclidean distances\n",
    "        #Placeholders for input\n",
    "        v1 = tf.placeholder(\"float\", [dim])\n",
    "        v2 = tf.placeholder(\"float\", [dim])\n",
    "        euclid_dist = tf.sqrt(tf.reduce_sum(tf.pow(tf.sub(\n",
    "            v1, v2), 2)))\n",
    " \n",
    "        ##This node will figure out which cluster to assign a vector to,\n",
    "        ##based on Euclidean distances of the vector from the centroids.\n",
    "        #Placeholder for input\n",
    "        centroid_distances = tf.placeholder(\"float\", [noofclusters])\n",
    "        cluster_assignment = tf.argmin(centroid_distances, 0)\n",
    " \n",
    "        ##INITIALIZING STATE VARIABLES\n",
    " \n",
    "        ##This will help initialization of all Variables defined with respect\n",
    "        ##to the graph. The Variable-initializer should be defined after\n",
    "        ##all the Variables have been constructed, so that each of them\n",
    "        ##will be included in the initialization.\n",
    "        init_op = tf.initialize_all_variables()\n",
    " \n",
    "        #Initialize all variables\n",
    "        sess.run(init_op)\n",
    " \n",
    "        ##CLUSTERING ITERATIONS\n",
    " \n",
    "        #Now perform the Expectation-Maximization steps of K-Means clustering\n",
    "        #iterations. To keep things simple, we will only do a set number of\n",
    "        #iterations, instead of using a Stopping Criterion.\n",
    "        noofiterations = 100\n",
    "        for iteration_n in range(noofiterations):\n",
    " \n",
    "            ##EXPECTATION STEP\n",
    "            ##Based on the centroid locations till last iteration, compute\n",
    "            ##the _expected_ centroid assignments.\n",
    "            #Iterate over each vector\n",
    "            for vector_n in range(len(vectors)):\n",
    "                vect = vectors[vector_n]\n",
    "                #Compute Euclidean distance between this vector and each\n",
    "                #centroid. Remember that this list cannot be named\n",
    "                #'centroid_distances', since that is the input to the\n",
    "                #cluster assignment node.\n",
    "                distances = [sess.run(euclid_dist, feed_dict={\n",
    "                    v1: vect, v2: sess.run(centroid)})\n",
    "                             for centroid in centroids]\n",
    "                #Now use the cluster assignment node, with the distances\n",
    "                #as the input\n",
    "                assignment = sess.run(cluster_assignment, feed_dict = {\n",
    "                    centroid_distances: distances})\n",
    "                #Now assign the value to the appropriate state variable\n",
    "                sess.run(cluster_assigns[vector_n], feed_dict={\n",
    "                    assignment_value: assignment})\n",
    " \n",
    "            ##MAXIMIZATION STEP\n",
    "            #Based on the expected state computed from the Expectation Step,\n",
    "            #compute the locations of the centroids so as to maximize the\n",
    "            #overall objective of minimizing within-cluster Sum-of-Squares\n",
    "            for cluster_n in range(noofclusters):\n",
    "                #Collect all the vectors assigned to this cluster\n",
    "                assigned_vects = [vectors[i] for i in range(len(vectors))\n",
    "                                  if sess.run(assignments[i]) == cluster_n]\n",
    "                #Compute new centroid location\n",
    "                new_location = sess.run(mean_op, feed_dict={\n",
    "                    mean_input: array(assigned_vects)})\n",
    "                #Assign value to appropriate variable\n",
    "                sess.run(cent_assigns[cluster_n], feed_dict={\n",
    "                    centroid_value: new_location})\n",
    " \n",
    "        #Return centroids and assignments\n",
    "        centroids = sess.run(centroids)\n",
    "        assignments = sess.run(assignments)\n",
    "        return centroids, assignments\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
